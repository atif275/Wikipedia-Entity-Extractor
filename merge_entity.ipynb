{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import wikipediaapi\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tiktoken\n",
    "from urllib.parse import unquote\n",
    "from urllib.request import urlopen\n",
    "# Cell to import necessary libraries\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_structured_output_runnable,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the language model\n",
    "\n",
    "def merge_json_files(directory_path):\n",
    "    \"\"\"Merge all JSON files in a directory into a single JSON list.\"\"\"\n",
    "    merged_data = []\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"No directory found at {directory_path}\")\n",
    "        return merged_data\n",
    "\n",
    "    for file in os.listdir(directory_path):\n",
    "        if file.endswith('.json'):\n",
    "            with open(os.path.join(directory_path, file), 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if data:  # Ensure that data is not empty\n",
    "                        merged_data.extend(data)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON from file {file}: {e}\")\n",
    "    return merged_data\n",
    "\n",
    "def process_title_entities(title_directory):\n",
    "    \"\"\"Process all entity JSON files for a given title.\"\"\"\n",
    "    merged_data = merge_json_files(title_directory)\n",
    "    if not merged_data:\n",
    "        print(\"No data found to merge.\")\n",
    "        return\n",
    "\n",
    "    title = os.path.basename(title_directory)\n",
    "    # Save the merged data\n",
    "    merged_dir = os.path.join('data/Merged_Entity_json', title)\n",
    "    os.makedirs(merged_dir, exist_ok=True)\n",
    "    merged_file_path = os.path.join(merged_dir, f\"{title}_Merged.json\")\n",
    "    with open(merged_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged_data, f, indent=4)\n",
    "    print(f\"Merged data saved to {merged_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "title_directory = 'data/Entity_json/Interstellar (film)'  # Specify the subfolder for a specific title\n",
    "process_title_entities(title_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
